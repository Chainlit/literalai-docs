---
title: Settings
icon: gear
---

## LLM Credentials

### Supported providers

Literal AI supports all major LLM providers:
- OpenAI
- Mistral
- Anthropic
- Google
- Azure OpenAI
- Amazon Bedrock
- Groq

Adding a credential is as simple as providing an API key:
<Frame caption="Add a credential">
    <img src="/images/add-credentials.gif" alt="Add a credential" />
</Frame>

<Tip>
Literal AI comes with a set of pre-configured models, but you can add your own.  
*Custom Models* should be the list of models you fine-tuned on specific providers.
</Tip>

<Info>
All credentials can be **used** by any Admin or AI Engineer on your team.  
Once added, credentials are not visible anymore. Admins may edit or delete credentials.
</Info>

**Azure OpenAI** and **Amazon Bedrock** have additional fields to configure.

#### Azure OpenAI
For Azure OpenAI, you need to map the Azure OpenAI endpoint to the following format:

`https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2024-06-01`

For instance, 
`https://my_instance.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-06-01`

would map to the following Literal AI provider:
<Frame caption="Azure OpenAI endpoint"  >
  <img src="/images/azureopenai.png" alt="An example of an Azure OpenAI endpoint." />
</Frame>

<Note>
No need to add a base URL to the endpoint!
</Note>

### Custom providers

If your LLM provider does not fall into one of the above, you may define your own, custom. 

In addition to the API key, you provide a base URL and the available models.

<Note>
The chat completions endpoint should follow OpenAI's API format.
</Note>

<Frame caption="Custom provider">
  <img src="/images/add-custom-provider.gif" alt="An example of a custom provider." />
</Frame>

<Warning>
Make sure your endpoint is reachable from the Internet!  
Especially if using LM Studio with `http://localhost:1234/v1` ðŸ˜‰
</Warning>
