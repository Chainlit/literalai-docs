---
title: "Dataset"
---

A dataset is an essential component in refining your LLM application's performance. It comprises a collection of input/output samples for conducting tests and validations.

A dataset consists of `Dataset Items`. A Dataset Item has an `input`, `expected output` and can contain `metadata`. The input, expected output and metadata of the items in a dataset should follow the same schema.


## Dataset Types
There are two types of datasets in Literal: Key Value and Generation. 

**Key Value** datasets can have any key-value pairs for input and expected output. This type of dataset can be used to for example store [Runs](/concepts/run) of agents, with an input (user query) and an expected output (LLM answer). An example of a Key Value dataset:

``` json

input = {
  "content": "Can you name a movie about space travel?"
}

expected_output = { 
  "content": "A movie about space travel is \"Interstellar\"." 
}
```


**Generation** datasets are a type of dataset that can store [Generation](/concepts/generation) items. Generation items have a chat history with `messages` from different `role`s and `content`. The expected output consists of a `role` and `content`. An example of a Generation Dataset Item:

``` json

input = {
  "messages": [{
    "role": "system"
    "content": "You are a helpful assistant." 
  }, {
    "role": "user"
    "content": "Can you name a movie about space travel?" 
  }] 
}

expected_output = { 
  "role": "assistant",
  "content": "A movie about space travel is \"Interstellar\"." 
}
```

## Creating Datasets and Dataset Items

### Via Literal UI

There are two ways you can create a new Dataset in the UI. 

1. Go to the Dataset tab, and create a new Dataset from there. You need to provide the Dataset Type, and give it a name. 
2. Go to an individual Run, Step or Generation that you want to add to a new dataset. You can create a new Dataset from here. 

To add items to your dataset, go to indivual Runs, Steps or Generations and click on `"Add to Dataset"`, and choose your preferred Dataset.

<Frame caption="Adding a Step to a Dataset">
  <img
    src="/images/add-run-to-dataset.png"
    alt="Adding a Step to a Dataset"
  />
</Frame>

<Frame caption="Screen of adding a Step to a Dataset">
  <img
    src="/images/add-to-dataset-popup.png"
    alt="Screen of adding a Step to a Dataset"
  />
</Frame>

To view your Datasets and its items, go to the Datasets tab.


### Via the SDKs
Our SDK facilitates dataset management, enabling both manual handling and the transformation of existing steps into actionable samples. This feature is designed for iterative development and fine-tuning of your application. For the complete API reference, check the [Python](/python-client/api-reference/dataset) and [TypeScript](/typescript-client/api-reference/dataset) SDK pages. Note: Dataset functions of the Python client are only possible synchronously. 

#### Create a dataset

<CodeGroup>
```python Python
from literalai import LiteralClient
import os

client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))

# create a new dataset
dataset = client.api.create_dataset(
  name="Foo", 
  description="A dataset to store samples.", 
  metadata={"isDemo": True},
  type="key_value" # Default type is "key_value", other is "generation"
)
```
```typescript TypeScript
import { LiteralClient, Thread } from "@literalai/client";

const client = new LiteralClient(process.env["LITERAL_API_KEY"]);

async function main() {
    const dataset = await client.api.createDataset({
        name: 'Foo',
        description: 'A dataset to store samples.',
        metadata: { isDemo: true },
        type: 'key_value' // other option: 'Generation'
    });
}
main();
```
</CodeGroup>

#### Create a dataset item

Now that we have a dataset, we can create dataset items. There are two ways to add items via the SDK. One is manually adding items in the code, the other option is to add existing Steps, Runs or Generations to the dataset. 

<CodeGroup>
```python Python
from literalai import LiteralClient
import os

client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))

# option 1: add local items
dataset_item = client.api.create_dataset_item(
  dataset_id = "<DATASET_ID>", # dataset.id
  input = { "content": "What is literal?" },
  expected_output = { "content": "Literal is an observability solution." }
)

# option 2: add existing steps, runs, generations
dataset_item = client.api.add_step_to_dataset(
  dataset_id = "<DATASET_ID>", # dataset.id
  step_id = "step_id" # reference to a step, run or generation
)
dataset_item = client.api.add_generation_to_dataset(
  dataset_id = "<DATASET_ID>", # dataset.id
  generation_id = "generation_id" # reference to a step, run or generation
)
```

```typescript TypeScript
import { LiteralClient, Thread } from "@literalai/client";

const client = new LiteralClient(process.env["LITERAL_API_KEY"]);

// option 1: add local items
const datasetId = "<DATASET_ID>";
const item = {
    input: { content: "What is literal?" },
    expectedOutput: { content: "Literal is an observability solution." },
};

const start = async function() {
    const datasetItem = await client.api.createDatasetItem(
        datasetId, 
        item
    );
}
start();

// option 2: add existing steps, runs, generations
const stepId = "<STEP_ID>";  // reference to a step
async function main() {
    const datasetItem = await client.api.addStepToDataset(
        datasetId,
        stepId
    );
};
main();
```
</CodeGroup>

#### Get a dataset

<CodeGroup>
```python Python
from literalai import LiteralClient
import os

client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))

dataset = sdk.api.get_dataset(id="<DATASET_ID>")

for item in dataset.items:
  pass
```
```typescript TypeScript
import { LiteralClient, Thread } from "@literalai/client";

const client = new LiteralClient(process.env["LITERAL_API_KEY"]);

async function main() {
    const dataset = await client.api.getDataset({id: "<DATASET_ID>"});

    dataset?.items.forEach((item) => {
        console.log(item.id)
    });
};

main();
```
</CodeGroup>


## Run experiments

Once you have created a populated Dataset, you can start running [evaluations](/concepts/evaluation).