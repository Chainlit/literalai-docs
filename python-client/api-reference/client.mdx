<a id="literalai.client"></a>


<a id="literalai.client.BaseLiteralClient"></a>

## BaseLiteralClient

```python
class BaseLiteralClient()
```

Base class for LiteralClient and AsyncLiteralClient.

**Example**:

```python
from literalai import LiteralClient, AsyncLiteralClient

# Initialize the client
client = LiteralClient(api_key="your_api_key_here")
async_client = AsyncLiteralClient(api_key="your_api_key_here")
```

**Attributes**:

<ResponseField name="api" type="Union[LiteralAPI, AsyncLiteralAPI]">The API client used for communication with Literal AI.</ResponseField>
<ResponseField name="disabled" type="bool">Flag indicating whether the client is disabled.</ResponseField>
<ResponseField name="event_processor" type="EventProcessor">Processor for handling events.</ResponseField>

<a id="literalai.client.BaseLiteralClient.instrument_openai"></a>

#### instrument\_openai

```python
def instrument_openai()
```

Instruments the OpenAI SDK so that all LLM calls are logged to Literal AI.

<a id="literalai.client.BaseLiteralClient.instrument_mistralai"></a>

#### instrument\_mistralai

```python
def instrument_mistralai()
```

Instruments the Mistral AI SDK so that all LLM calls are logged to Literal AI.

<a id="literalai.client.BaseLiteralClient.instrument_llamaindex"></a>

#### instrument\_llamaindex

```python
def instrument_llamaindex()
```

Instruments the Llama Index framework so that all RAG & LLM calls are logged to Literal AI.

<a id="literalai.client.BaseLiteralClient.langchain_callback"></a>

#### langchain\_callback

```python
def langchain_callback(to_ignore: Optional[List[str]] = None,
                       to_keep: Optional[List[str]] = None,
                       **kwargs: Any)
```

Creates a Callback for Langchain that logs all LLM calls to Literal AI.

**Arguments**:

<ResponseField name="to_ignore" type="Optional[List[str]]">Runs to ignore to declutter logging.</ResponseField>
<ResponseField name="to_keep" type="Optional[List[str]]">Runs to keep within ignored runs.</ResponseField>
  

**Returns**:

<ResponseField name="LangchainTracer">The callback to use in Langchain's invoke methods.</ResponseField>

<a id="literalai.client.BaseLiteralClient.start_step"></a>

#### start\_step

```python
def start_step(name: str = "",
               type: Optional[TrueStepType] = None,
               id: Optional[str] = None,
               parent_id: Optional[str] = None,
               thread_id: Optional[str] = None,
               root_run_id: Optional[str] = None,
               **kwargs)
```

Creates a step and starts it in the current context. To log it on Literal AI use `.end()`.
This is used to create Agent steps. For conversational messages use `message` instead.

**Arguments**:

<ResponseField name="name" type="Optional[str]">The name of the step to create.</ResponseField>
<ResponseField name="type" type="TrueStepType">The type of the step. Must be one of the following :</ResponseField>
  "run", "tool", "llm", "embedding", "retrieval","rerank", "undefined".
<ResponseField name="id" type="Optional[str]">The id of the step to create.</ResponseField>
<ResponseField name="parent_id" type="Optional[str]">The id of the parent step.</ResponseField>
<ResponseField name="thread_id" type="Optional[str]">The id of the parent thread.</ResponseField>
<ResponseField name="root_run_id" type="Optional[str]">The id of the root run.</ResponseField>
  

**Returns**:

<ResponseField name="Step">the created step.</ResponseField>

<a id="literalai.client.BaseLiteralClient.get_current_step"></a>

#### get\_current\_step

```python
def get_current_step()
```

Gets the current step from the context.

<a id="literalai.client.BaseLiteralClient.get_current_thread"></a>

#### get\_current\_thread

```python
def get_current_thread()
```

Gets the current thread from the context.

<a id="literalai.client.BaseLiteralClient.get_current_root_run"></a>

#### get\_current\_root\_run

```python
def get_current_root_run()
```

Gets the current root run from the context.

<a id="literalai.client.BaseLiteralClient.reset_context"></a>

#### reset\_context

```python
def reset_context()
```

Resets the context, forgetting active steps & setting current thread to None.

<a id="literalai.client.BaseLiteralClient.flush_and_stop"></a>

#### flush\_and\_stop

```python
def flush_and_stop()
```

Sends all threads and steps to the Literal AI API. Waits synchronously for all API calls to be done.

<a id="literalai.client.LiteralClient"></a>

## LiteralClient

```python
class LiteralClient(BaseLiteralClient)
```

Synchronous client for interacting with the Literal AI API.

**Example**:

```python
from literalai import LiteralClient
# Initialize the client
client = LiteralClient(api_key="your_api_key_here")
```

<a id="literalai.client.AsyncLiteralClient"></a>

## AsyncLiteralClient

```python
class AsyncLiteralClient(BaseLiteralClient)
```

Asynchronous client for interacting with the Literal AI API.

**Example**:

```python
from literalai import AsyncLiteralClient
# Initialize the client
async_client = AsyncLiteralClient(api_key="your_api_key_here")
```

